Metadata-Version: 2.4
Name: media-analyzer
Version: 0.1.0
Summary: AI-powered media analysis tool for images and audio using multiple LLM providers
Classifier: Development Status :: 4 - Beta
Classifier: Intended Audience :: Developers
Classifier: License :: OSI Approved :: MIT License
Classifier: Programming Language :: Python :: 3
Classifier: Programming Language :: Python :: 3.12
Requires-Python: >=3.12
Description-Content-Type: text/markdown
Requires-Dist: click>=8.1.0
Requires-Dist: pillow>=10.0.0
Requires-Dist: litellm>=1.72.2
Requires-Dist: aiofiles>=24.0.0
Requires-Dist: python-dotenv>=1.0.0
Requires-Dist: pyyaml>=6.0.0
Requires-Dist: tenacity>=8.0.0
Requires-Dist: tqdm>=4.66.0
Requires-Dist: loguru>=0.7.2
Requires-Dist: pandas>=2.0.0
Requires-Dist: rich>=13.0.0
Requires-Dist: nest-asyncio>=1.6.0
Requires-Dist: ffmpeg-python>=0.2.0
Requires-Dist: pydub>=0.25.0
Requires-Dist: pytest-cov>=6.2.1
Requires-Dist: pytest>=8.4.1
Requires-Dist: pytest-asyncio>=1.0.0

# Media Analyzer CLI

AI-powered image analysis tool using multiple LLM providers through LiteLLM. Analyze single images or process batches with customizable prompts and output formats.

## Features

- ü§ñ **Multi-model Support**: Use Gemini, OpenAI, Claude, and more through LiteLLM
- üìÅ **Batch Processing**: Analyze single images or entire directories
- ‚ö° **Async Processing**: Concurrent analysis with configurable concurrency limits
- üìä **Multiple Output Formats**: JSON, Markdown, and CSV export
- üéØ **Custom Prompts**: Use predefined or custom analysis prompts
- üìà **Progress Tracking**: Real-time progress bars for batch operations
- üîÑ **Retry Logic**: Automatic retries with exponential backoff
- ‚öôÔ∏è **Flexible Configuration**: Environment variables and YAML config support

## Quick Start

### Installation

```bash
# Clone the repository
git clone <repository-url>
cd media-analyzer

# Install with uv (recommended)
uv sync

# That's it! No virtual environment activation needed
```

### Basic Usage

```bash
# Set your API key (choose one)
export OPENAI_API_KEY="sk-your-key-here"
export GEMINI_API_KEY="your-google-key-here"
export ANTHROPIC_API_KEY="sk-ant-your-key-here"

# Analyze a single image
uv run media-analyzer --type image --model gemini/gemini-1.5-flash --path photo.jpg

# Analyze with custom prompt and word count
uv run media-analyzer --type image --model gpt-4o --path image.png \
  --prompt "Describe the technical aspects of this image" --word-count 200

# Batch process a directory of images
uv run media-analyzer --type image --model claude-3-sonnet-20240229 --path ./photos/ \
  --output markdown --output-file results.md --concurrency 3

# Transcribe audio file
uv run media-analyzer --type audio --model whisper-1 --path audio.mp3 --audio-mode transcript

# Analyze audio content with description
uv run media-analyzer --type audio --model gpt-4o --path podcast.wav \
  --audio-mode description --prompt "Summarize the key points discussed"
```

## Installation Options

### Option 1: Modern UV Setup (Recommended)

```bash
# Install uv if you haven't already
curl -LsSf https://astral.sh/uv/install.sh | sh

# Clone and setup
git clone <repository-url>
cd media-analyzer
uv sync

# Start using immediately
uv run media-analyzer --help
```

### Option 2: Traditional Setup

```bash
git clone <repository-url>
cd media-analyzer
python -m venv .venv
source .venv/bin/activate  # On Windows: .venv\Scripts\activate
pip install -e .
```

## Configuration

### Environment Variables

Create a `.env` file in the project root:

```bash
# Copy the example file
cp .env.example .env

# Edit with your API keys
OPENAI_API_KEY=sk-your-openai-key
GEMINI_API_KEY=your-google-key
ANTHROPIC_API_KEY=sk-ant-your-anthropic-key

# Optional settings
DEFAULT_MODEL=gemini/gemini-1.5-flash
DEFAULT_WORD_COUNT=100
MAX_CONCURRENCY=5
```

### YAML Configuration

For advanced configuration, copy and customize the YAML config:

```bash
cp config.yaml.example config.yaml
```

Edit `config.yaml` to set custom prompts, file size limits, and more.

## Usage Examples

### Single Image Analysis

```bash
# Basic image analysis
uv run media-analyzer --type image --model gemini/gemini-1.5-flash --path photo.jpg

# Save image analysis as markdown report
uv run media-analyzer --type image --model gpt-4o --path diagram.png \
  --output markdown --output-file analysis.md

# Custom prompt with specific word count
uv run media-analyzer --type image --model claude-3-sonnet-20240229 --path chart.jpg \
  --prompt "Analyze this chart focusing on data insights" --word-count 300
```

### Batch Processing

```bash
# Process all images in a directory
uv run media-analyzer --type image --model gemini/gemini-1.5-flash --path ./images/ \
  --output text --output-file results.txt

# Recursive directory processing with concurrency
uv run media-analyzer --type image --model gpt-4-vision-preview --path ./dataset/ \
  --recursive --concurrency 5 --output json --output-file batch_results.json

# Process with progress tracking and custom settings
uv run media-analyzer --type image --model gemini/gemini-1.5-flash --path ./photos/ \
  --word-count 150 --log-level INFO --concurrency 3

### Audio Processing

```bash
# Transcribe audio files
uv run media-analyzer --type audio --model whisper-1 --path ./audio/ \
  --audio-mode transcript --output text --output-file transcripts.txt

# Analyze audio content with batch processing
uv run media-analyzer --type audio --model gpt-4o --path ./podcasts/ \
  --audio-mode description --recursive --concurrency 2 --word-count 200
```

### Output Formats

#### JSON Output

```bash
uv run media-analyzer --type image --model gemini/gemini-1.5-flash --path image.jpg --output json
```

#### Markdown Report

```bash
uv run media-analyzer --type image --model gpt-4o --path image.jpg --output markdown
```

#### Text Output for Data Analysis

```bash
uv run media-analyzer --type image --model claude-3-sonnet-20240229 --path ./images/ --output text
```

### Audio Analysis

#### Audio Transcription

```bash
# Transcribe a single audio file
uv run media-analyzer --type audio --model whisper-1 --path recording.mp3 --audio-mode transcript

# Batch transcribe audio files  
uv run media-analyzer --type audio --model whisper-1 --path ./audio_files/ --audio-mode transcript --output text
```

#### Audio Content Analysis

```bash
# Analyze audio content with description
uv run media-analyzer --type audio --model gpt-4o --path podcast.wav --audio-mode description \
  --prompt "Summarize the main topics and key insights" --word-count 200

# Batch analyze audio with custom prompts
uv run media-analyzer --type audio --model claude-3-sonnet-20240229 --path ./meetings/ \
  --audio-mode description --recursive --concurrency 2
```

## Supported Models

The tool supports any model available through [LiteLLM](https://docs.litellm.ai/docs/providers). Popular options include:

### OpenAI Models

**Vision Models:**
- `gpt-4o`
- `gpt-4-vision-preview`
- `gpt-4-turbo`

**Audio Models:**
- `whisper-1` (for transcription)
- `gpt-4o` (for audio content analysis)

### Google Models

- `gemini/gemini-1.5-flash`
- `gemini/gemini-1.5-pro`
- `gemini/gemini-pro-vision`

### Anthropic Models

- `claude-3-sonnet-20240229`
- `claude-3-opus-20240229`
- `claude-3-haiku-20240307`

### Other Providers

- Azure OpenAI
- AWS Bedrock
- Cohere
- And many more through LiteLLM

## Command Line Options

```
Options:
  -t, --type [image|audio]        Analysis type: image or audio (required)
  -m, --model TEXT                LiteLLM model (required)
  -p, --path PATH                 Media file or directory path (required)
  --audio-mode [transcript|description] Audio analysis mode (required for audio type)
  -w, --word-count INTEGER        Target description word count [default: 100]
  --prompt TEXT                   Custom analysis prompt
  -o, --output [json|markdown|text] Output format [default: json]
  --output-file TEXT              Save results to file
  -r, --recursive                 Process directories recursively
  -c, --concurrency INTEGER       Concurrent requests [default: 3]
  --log-level [DEBUG|INFO|WARNING|ERROR] Logging level [default: INFO]
  -v, --verbose                   Show detailed output including model info
  --version                       Show version and exit
  --help                          Show help and exit
```

## Development

This project follows strict development standards outlined in the [Development Guidelines](#development-guidelines) section above. Please review those principles before contributing.

### Running Tests

**Important**: All tests require valid API keys. Tests will fail immediately if API keys are missing - this is intentional to ensure test coverage accuracy.

```bash
# Set up API keys first (required)
export OPENAI_API_KEY="sk-your-key-here"
export GEMINI_API_KEY="your-google-key-here"
export ANTHROPIC_API_KEY="sk-ant-your-key-here"

# Run all tests (will fail fast if API keys missing)
uv run pytest

# Run with coverage
uv run pytest --cov

# Run specific test file
uv run pytest tests/test_cli.py -v

# Run integration tests specifically
uv run pytest -m integration -v
```

### Code Quality

```bash
# Format code
uv run black .

# Lint code
uv run ruff check .

# Type checking
uv run mypy src/

# Run all quality checks
uv run pytest && uv run black . && uv run ruff check . && uv run mypy src/
```

### Adding Dependencies

```bash
# Add runtime dependency
uv add pillow

# Add development dependency
uv add --dev pytest-mock

# Update all dependencies
uv sync
```

## Development Guidelines

This project follows strict development principles prioritizing reliability and explicit error handling over graceful degradation.

### Core Principles

1. **Fail Fast Philosophy**
   - No graceful degradation when components malfunction
   - Raise exceptions immediately for any error condition
   - Better to fail explicitly than continue with broken functionality

2. **Strict Testing Standards**
   - Never skip tests due to missing dependencies or API keys
   - All tests must execute with real integrations when possible
   - Raise clear exceptions if required API keys are missing
   - Integration tests are mandatory, not optional

3. **Explicit Error Handling**
   - Use exceptions for all error conditions
   - No silent failures or try/except blocks that continue on error
   - API key validation must raise descriptive exceptions
   - File system errors should immediately abort operations

### Error Handling Rules

```python
# ‚úÖ Good: Explicit failure
def analyze_image(api_key: str, image_path: Path):
    if not api_key:
        raise ValueError("API key is required for image analysis")
    if not image_path.exists():
        raise FileNotFoundError(f"Image file not found: {image_path}")
    # Continue with analysis...

# ‚ùå Bad: Silent degradation
def analyze_image(api_key: str, image_path: Path):
    if not api_key:
        logger.warning("No API key provided, skipping analysis")
        return None  # Silent failure
```

### Testing Philosophy

```python
# ‚úÖ Good: Fail if API key missing
def test_image_analysis():
    api_key = os.getenv("OPENAI_API_KEY")
    if not api_key:
        pytest.fail("OPENAI_API_KEY required for integration tests")
    # Run real test...

# ‚ùå Bad: Skip test
def test_image_analysis():
    api_key = os.getenv("OPENAI_API_KEY")
    if not api_key:
        pytest.skip("No API key available")  # Hides test coverage gaps
```

### Component Reliability

- **Configuration**: Fail immediately if required config is missing
- **API Clients**: Raise exceptions on authentication or connection failures
- **File Operations**: Abort on any file system errors
- **Model Loading**: Fail fast if models are unavailable or incompatible

This approach ensures that:
- Issues are discovered early in development
- Production deployments are more reliable
- Test coverage accurately reflects real usage scenarios
- Debugging is easier with explicit error messages

## Examples

See the `examples/` directory for:

- **`sample_usage.py`**: Comprehensive programmatic usage examples
- Different analysis scenarios and configuration options
- Batch processing examples with progress tracking

Run the examples:

```bash
uv run python examples/sample_usage.py
```

## Troubleshooting

This project follows a **fail-fast philosophy**. When errors occur, the application will immediately terminate with clear error messages rather than attempting graceful recovery.

### Common Issues

1. **API Key Errors**

   **Expected Behavior**: Application fails immediately with descriptive error message.
   
   ```bash
   # Verify API keys are properly set
   echo $OPENAI_API_KEY
   echo $GEMINI_API_KEY
   echo $ANTHROPIC_API_KEY
   
   # Expected error if missing:
   # ValueError: API key is required for model 'gpt-4o'
   ```

2. **Model Not Found**

   **Expected Behavior**: Immediate failure with specific model name.
   
   ```bash
   # Check LiteLLM documentation for correct model names
   # https://docs.litellm.ai/docs/providers
   
   # Example error:
   # litellm.exceptions.NotFoundError: Model 'invalid-model' not found
   ```

3. **Media Format Issues**

   **Expected Behavior**: File validation fails immediately before API calls.
   
   ```bash
   # Supported image formats: .jpg, .jpeg, .png, .gif, .bmp, .tiff, .webp
   # Supported audio formats: .mp3, .wav, .m4a, .flac, .ogg
   # Image size limits (default: 10MB), Audio size limits (default: 100MB)
   
   # Example errors:
   # FileNotFoundError: Media file not found: /path/to/missing.jpg
   # ValueError: File size exceeds 10MB limit: large_image.png  
   # ValueError: Audio file exceeds 100MB limit: long_recording.wav
   # ValueError: Unsupported format: .txt
   ```

4. **Audio-Specific Errors**

   **Expected Behavior**: Audio mode validation and transcription failures.
   
   ```bash
   # Example errors:
   # ClickException: --audio-mode is required when --type is 'audio'
   # ClickException: --audio-mode should not be used when --type is 'image'
   # ValueError: Invalid audio file: corrupted.mp3
   ```

5. **Import Errors**
   
   **Expected Behavior**: Module import failures prevent startup.
   
   ```bash
   # Make sure you're using uv run or have activated the virtual environment
   uv run media-analyzer --help
   
   # Expected error if not properly installed:
   # ModuleNotFoundError: No module named 'media_analyzer_cli'
   ```

### Error Philosophy

Unlike many applications that attempt to gracefully handle errors, this tool is designed to:

- **Fail immediately** when dependencies are missing
- **Reject invalid inputs** before processing begins  
- **Abort operations** on any component failure
- **Provide explicit error messages** for all failure modes

This approach ensures that issues are discovered early and fixed properly rather than masked by fallback behavior.

### Debug Mode

Enable detailed logging for troubleshooting:

```bash
uv run media-analyzer --type image --model gemini/gemini-1.5-flash --path image.jpg --log-level DEBUG
```

## Performance

### Benchmarks

- **Single Image**: < 5 seconds typical response time
- **Batch Processing**: ~100 images in 3-5 minutes (concurrency=5)
- **Memory Usage**: < 500MB for large batch operations

### Optimization Tips

1. **Adjust Concurrency**: Start with 3-5, increase based on API limits
2. **File Size**: Optimize images to under 5MB for faster processing
3. **Batch Size**: Process 50-100 images per batch for optimal performance

## License

MIT License - see LICENSE file for details.

## Contributing

1. Fork the repository
2. Create a feature branch
3. Make your changes
4. Run tests: `uv run pytest`
5. Submit a pull request

## Changelog

### v0.1.0

- Initial release
- Multi-model support via LiteLLM
- Batch processing with concurrency
- Multiple output formats (JSON, Markdown, CSV)
- Progress tracking with tqdm
- Comprehensive error handling and retries
- Modern UV package management
